---
title: "COD Reproducibility Report"
output:
  html_document:
    toc: true
    toc_float: true
---

#### Article ID: gIjYG
#### Pilot: Minyoung Lee
#### Co-pilot: Tom Hardwicke  
#### Start date: 03/24/2017
#### End date: 03/28/2017

-------

#### Methods summary: 
<!-- [Write a brief summary of the methods underlying the target outcomes written in your own words] -->

Participants searched for a target in complex scenes containing social or non-social distractors. The search time and whether or not the distractor was fixated first after scene onset (first look) were measured in each search trial. The search time and first look in social and non-social trials were compared over three blocks. Learning in visual search waas operationalized as decreasing search time over blocks. Using AIC model averaging with search time, the interaction between disctractor type and block and the main effects were investigated.

------

#### Target outcomes: 
<!-- [Insert the target outcomes identified in targetOutcomes.md]   -->
> 3.1. Visual search

> Manual and eye-tracking measures provided converging evidence for social stimuli being more distracting than non-social stimuli, with the effects interacting with learning over successive blocks (see Table 1 for descriptives).

> 3.1.1. Manual search time (s)

> We first investigated whether participants learned target locations across blocks, and whether distractor type affected this learning. Decreasing search time over blocks indicated learning and there was a moderating effect of distractor on learning slopes. AIC model averaging with manual response times during the visual search task revealed that the coefficient estimates for block as well as the distractor-by-block interaction term were significantly different from zero, indicating they had significant effects on the model (Table 2). A repeated-measures ANOVA with two within-subject factors (distractor: social, non-social; block: one, two, three), revealed a main effect of block, F(1.47, 52.89) = 395.23, p = < 0.001, η2 = 0.92, driven by decreasing search time across blocks. There was no main effect of distractor on search time, F(1, 36) = 0.38, p > 0.250, η2 = 0.01, but there was a significant distractor-by-block interaction, F(1.94, 69.98) = 3.78, p = 0.029, η2 = 0.10. Although Bonferroni-adjusted post hoc tests revealed no significant differences in search time between social and non-social scenes in each block separately (block one: p = 0.218, block two: p = 0.215, block three: p = 0.135), and highly significant differences between blocks for both social and non-social scenes separately (p < 0.001), there was a significant interaction between distractor and block in the linear contrasts, F(1, 36) = 5.13, p = 0.030, η2 = 0.13, suggesting a difference in slope across blocks between social and non-social scenes.

------

[The chunk below sets up some formatting options for the R Markdown document]

```{r global_options, include=FALSE}
knitr::opts_chunk$set(echo=TRUE, warning=FALSE, message=FALSE)
```

## Step 1: Load packages

[Some useful packages are being loaded below. You can add any additional ones you might need too.]

```{r}
library(tidyverse) # for data munging
library(knitr) # for kable table formating
library(haven) # import and export 'SPSS', 'Stata' and 'SAS' Files
library(readxl) # import excel files
library(CODreports) # custom report functions
library(MuMIn)
library(lme4)
library(ez)
```

## Step 2: Load data

```{r}
d <- read.csv("data/data.csv")
```

## Step 3: Tidy data

```{r}
d.tidy <- select(d, Sbj,social,block,learn_ACC,learn_total_search,Total_first_look,AQ,SAS)

d.tidy <- d.tidy %>%
  rename(sbj = Sbj,
         accurate = learn_ACC,
         rt = learn_total_search,
         first = Total_first_look,
         distractor = social)
```

## Step 4: Run analysis

### Pre-processing

<!-- [you can remove this section if no pre-processing is required] -->

```{r}
d.tidy$distractor <- factor(d.tidy$distractor)
d.tidy$distractor <- factor(d.tidy$distractor, levels(d.tidy$distractor)[c(2,1)], labels = c("social","non-social")) 
d.tidy$sbj <- factor(d.tidy$sbj)
# d.tidy$block <- factor(d.tidy$block) # unclear what the authors did...
```

### Descriptive statistics
```{r echo=FALSE, include=FALSE}
printstats = function(val) {
    return(sprintf('%.2f', val))
}
```

```{r}
se <- function(x) sd(x)/sqrt(length(x))

# accuracy
tbl <- d.tidy %>% group_by(sbj, distractor, block) %>%
  summarise(accuracy = sum(accurate)/n()*100)  %>%
  group_by(distractor, block, add=FALSE) %>%
  summarise(meanAccuracy = mean(accuracy), se_accuracy = se(accuracy))
# RT and First look in accurate trials
tbl2 <- d.tidy %>% group_by(sbj, distractor, block) %>%
  filter(accurate==1) %>%
  summarise(RT = mean(rt), First = sum(first,na.rm=TRUE)/sum(!is.nan(first))*100) %>%
  group_by(distractor,block, add=FALSE) %>%
  summarise(meanRT = mean(RT), se_RT = se(RT), meanFirst = mean(First), se_first = se(First))
```

|  Distractor  |  Block  |  RT (s)  |  Accuracy (%)  |  First looks (%)  |
|:------------|:-------|:--------|:--------------|:-----------------|
|   Social   |  1  | `r printstats(tbl2$meanRT[1])` (`r printstats(tbl2$se_RT[1])`) | `r printstats(tbl$meanAccuracy[1])` (`r printstats(tbl$se_accuracy[1])`) | `r printstats(tbl2$meanFirst[1])` (`r printstats(tbl2$se_first[1])`) |
|      |  2  | `r printstats(tbl2$meanRT[2])` (`r printstats(tbl2$se_RT[2])`) | `r printstats(tbl$meanAccuracy[2])` (`r printstats(tbl$se_accuracy[2])`) | `r printstats(tbl2$meanFirst[2])` (`r printstats(tbl2$se_first[2])`) |
|      |  3  | `r printstats(tbl2$meanRT[3])` (`r printstats(tbl2$se_RT[3])`) | `r printstats(tbl$meanAccuracy[3])` (`r printstats(tbl$se_accuracy[3])`) | `r printstats(tbl2$meanFirst[3])` (`r printstats(tbl2$se_first[3])`) |
|   Non-social   |  1  | `r printstats(tbl2$meanRT[4])` (`r printstats(tbl2$se_RT[4])`) | `r printstats(tbl$meanAccuracy[4])` (`r printstats(tbl$se_accuracy[4])`) | `r printstats(tbl2$meanFirst[4])` (`r printstats(tbl2$se_first[4])`) |
|      |  2  | `r printstats(tbl2$meanRT[5])` (`r printstats(tbl2$se_RT[5])`) | `r printstats(tbl$meanAccuracy[5])` (`r printstats(tbl$se_accuracy[5])`) | `r printstats(tbl2$meanFirst[5])` (`r printstats(tbl2$se_first[5])`) |
|      |  3  | `r printstats(tbl2$meanRT[6])` (`r printstats(tbl2$se_RT[6])`) | `r printstats(tbl$meanAccuracy[6])` (`r printstats(tbl$se_accuracy[6])`) | `r printstats(tbl2$meanFirst[6])` (`r printstats(tbl2$se_first[6])`) |
       

```{r}
# discrepancy in RT in Social Block 2
compareValues(3.32, 3.33)
# discrepancy in Accuracy in Non-social Block 3
compareValues(98.12, 98.11)
# discrepancies in standard errors
# RT Standard Errors
compareValues(0.11, 0.17)
compareValues(0.06, 0.11)
compareValues(0.06, 0.08)
compareValues(0.11, 0.17)
compareValues(0.07, 0.14)
compareValues(0.07, 0.18)
# Accuracy Standard Errors
compareValues(0.45, 0.77)
compareValues(0.34, 0.59)
compareValues(0.32, 0.43)
compareValues(0.64, 0.78)
compareValues(0.33, 0.51)
compareValues(0.34, 0.64)
# First looks Standard Errors
compareValues(1.81, 2.44)
compareValues(1.39, 1.89)
compareValues(1.12, 1.49)
compareValues(1.27, 1.16)
compareValues(1.23, 1.09)
compareValues(1.17, 0.91)

```
```{r}
tbl3 <- d.tidy %>% group_by(sbj, distractor, block) %>%
  filter(accurate==1) %>%
  summarise(RT = mean(log(rt))) %>%
  group_by(distractor,block, add=FALSE) %>%
  summarise(meanRT = mean(RT), se_RT = se(RT))

tbl3 %>% ggplot(aes(x = block, y = meanRT, color = distractor)) +
  geom_pointrange(aes(ymin=meanRT-se_RT, ymax=meanRT+se_RT)) +
  geom_line() 
```

```{r}
tbl4 <- d.tidy %>% group_by(sbj) %>%
  filter(accurate==1) %>%
  summarise(First = sum(first,na.rm=TRUE)/sum(!is.nan(first))*100, AQ=mean(AQ))

tbl4 %>% ggplot(aes(x = AQ, y = First)) +
  geom_point() +
  geom_smooth(method=lm, se=FALSE) +
  xlim(0,35) +
  ylim(0,35)
```

### Inferential statistics

```{r}
d_filter <- filter(d.tidy, accurate==1)
# center and normalized AQ and SAS
d_filter$AQ <- scale(d_filter$AQ,center=TRUE,scale=TRUE)
d_filter$SAS <- scale(d_filter$SAS,center=TRUE,scale=TRUE)
d_filter$distractor <- factor(as.character(d_filter$distractor), levels=c("non-social","social"))

# the global model (all fixed effects and distractor as a random slope)
m <- lmer(rt ~ distractor * block * AQ * SAS + (1+distractor|sbj), data=d_filter)
# generating a set of candidate models with combinations of all terms
options(na.action="na.fail")
sub <- dredge(m, rank="AIC")
# model averaging
modavg <- model.avg(sub, rank="AIC")
# summary(modavg)
# mean estimates of the coefficients (theta) -> full
modavg$coefficients
# 95% confidence intervals (CI)
confint(modavg)
# Relative Influence (importance)
modavg$importance

```
INSUFFICIENT INFORMATION ERROR

I followed the procedures described in the supplementary material quoted below using the same statistical package. However, the current analysis failed to replicated the coefficients reported in the original paper.
> AIC modeling. Distractor was included as a random slope, to model potential individual differences in this variable of interest between participants. First, the global model containing all fixed and random effects was specified. Next, a subset of candidate models that contained all possible combinations of the fixed effects included in the global model were specified. These candidate models were ranked according to their AIC score (lower scores indicate better fit), and the delta AIC (Δi) in relation to the highest-ranking model as well as the Akaike weight (w) were calculated using the R package MuMIn (Bartón, 2015). Akaike weight based averaging over all candidate models allowed for the derivation of three values to be used for analysis. First, the mean estimates of the coefficients (θ) were calculated by averaging the estimates over all candidate models that included the θ of interest, weighted by w. Second, for each θ of interest the 95% confidence intervals (CI) were calculated in order to determine which coefficients were statistically significantly different from zero. Finally, the ‘Relative Influence’ (RI) was calculated as the summation of w across all models that included the variable of interest, as a further indication of the importance of each predictor. Model averaging in this way accounts for model selection uncertainty by incorporating all possible models as opposed to comparing step-wise two models at a time (Burnham & Anderson, 2002). (from Doherty et al. Supplemantary Material p.1).


```{r}
d_filter$blockf = factor(d_filter$block)
aov_rt <- ezANOVA(d_filter, dv=rt, wid=sbj, within=.(distractor,blockf),detailed=TRUE, type=3)
print(aov_rt)
# main effect of block
compareValues(395.23,284.76)
compareValues(0.92,aov_rt$ANOVA$ges[3])
# main effect of distractor
compareValues(0.38,0.92)
compareValues(0.01,aov_rt$ANOVA$ges[2])
# interaction
compareValues(3.78,2.36)
compareValues(0.029,aov_rt$ANOVA$p[4],isP=TRUE)
compareValues(0.10, aov_rt$ANOVA$ges[4])
```
 

```{r}
# Regression slopes...
subjects=unique(d_filter$sbj)
coefs_soc = rep(NA, length(subjects))
coefs_non = rep(NA, length(subjects))
c=1
for (i in subjects) {
  soc_tmp <- d_filter[d_filter$sbj==i & d_filter$distractor=="social",]
  non_tmp <- d_filter[d_filter$sbj==i & d_filter$distractor=="non-social",]
  reg_soc <- lm(log(rt) ~ block, soc_tmp, na.action=na.omit)
  reg_non <- lm(log(rt) ~ block, non_tmp, na.action=na.omit)
  
  coefs_soc[c] <- reg_soc$coefficients[[2]]
  coefs_non[c] <- reg_non$coefficients[[2]]
  c<-c+1
}

mean(coefs_non)
sd(coefs_non)
mean(coefs_soc)
sd(coefs_soc)

compareValues(-0.34,-0.31)
compareValues(0.10,0.08)

compareValues(-0.31,-0.28)
compareValues(0.08,0.08)

```
## Step 5: Conclusion

```{r}
codReport(Report_Type = 'pilot',
          Article_ID = 'gIjYG',
          Insufficient_Information_Errors = 1,
          Decision_Errors = 1,
          Major_Numerical_Errors = 15,
          Minor_Numerical_Errors = 5)
          
```

<!-- [Please also include a brief text summary describing your findings. If this reproducibility check was a failure, you should note any suggestions as to what you think the likely cause(s) might be.] -->
Although the current replication attempt reproduced some of the figures and descriptive statistics, it failed to reproduce major inferential statistics of the original study. A lot of coefficients were inconsistent with the reported value even though significance and the direction of effects in accord with the original findings. The discrepencies could have resulted from lack of detailed decrpitons of analyses being done in the original paper. For example, in AIC modeling detailed procedures including whether the authors included all candidate models or only a subset of models in the model averaging were underspecified. In addition, the authors did not mention about any data preprocessing which might have done in the original study. It is possible that the data entered into model averaging or ANOVA in this replication was different than the data entered in the original study.


[This function will output information about the package versions used in this report:]

```{r session_info, include=TRUE, echo=TRUE, results='markup'}
devtools::session_info()
```
